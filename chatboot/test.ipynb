{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5194234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a65f2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    name: str\n",
    "    age: str\n",
    "    skils: list[str]\n",
    "    result: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cf96fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting_node(state:AgentState)->AgentState:\n",
    "    greeting = f\"{state['name']}, welcome to the system!\"\n",
    "    return {\"result\":greeting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6cb9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_node(state:AgentState)->AgentState:\n",
    "    user_age=f\"You are {state['age']} years old!\"\n",
    "    return {\"result\": state[\"result\"] + user_age}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed6f4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def skills_node(state:AgentState)->AgentState:\n",
    "#     user_skills= \"You have skills in: \"+ \" \".join(state[\"skils\"])\n",
    "#     return {\"result\": state['result']+ user_skills}\n",
    "\n",
    "def skills_node(state: AgentState) -> AgentState:\n",
    "    skills = state[\"skils\"]          # ← make sure the key is spelled correctly!\n",
    "    \n",
    "    if not skills:                              # no skills listed\n",
    "        skills_str = \"no listed skills\"\n",
    "    elif len(skills) == 1:                      # exactly one skill\n",
    "        skills_str = skills[0]\n",
    "    elif len(skills) == 2:                      # two skills → “A and B”\n",
    "        skills_str = f\"{skills[0]} and {skills[1]}\"\n",
    "    else:                                       # three or more → “A, B, …, and Z”\n",
    "        skills_str = \", \".join(skills[:-1]) + f\" and {skills[-1]}\"\n",
    "    \n",
    "    user_skills = f\"You have skills in: {skills_str}\"\n",
    "    return {\"result\": state[\"result\"] + \" \" + user_skills}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bca3743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"greeting\",greeting_node)\n",
    "graph.add_node(\"user_age\",age_node)\n",
    "graph.add_node(\"skills\",skills_node)\n",
    "\n",
    "graph.add_edge(START, \"greeting\")\n",
    "graph.add_edge(\"greeting\",\"user_age\" )\n",
    "graph.add_edge(\"user_age\",\"skills\")\n",
    "graph.add_edge(\"skills\", END)\n",
    "\n",
    "workflow=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d773868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Linda',\n",
       " 'age': '31',\n",
       " 'skils': ['Python', 'Machine Learning', 'LangGraph'],\n",
       " 'result': 'Linda, welcome to the system!You are 31 years old! You have skills in: Python, Machine Learning and LangGraph'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state={\"name\":\"Linda\", \"age\": \"31\", \"skils\": [\"Python\", \"Machine Learning\", \"LangGraph\"]}\n",
    "\n",
    "workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "23ad854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain import hub\n",
    "import textwrap\n",
    "import os\n",
    "class AgentState2(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context:List[Document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c0f457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "    answer:str= Field(description=\"answer of user asked question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3b835831",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "structured_llm=llm.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f12f8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(state:AgentState2)->AgentState2:\n",
    "    base_dir = os.getcwd()\n",
    "    product_file_path = os.path.join(base_dir, \"./product_help.txt\")\n",
    "    product_loader = TextLoader(product_file_path)\n",
    "    product_docs = product_loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "    product_chunks = text_splitter.split_documents(product_docs)\n",
    "    for doc in product_chunks:\n",
    "            doc.metadata[\"type\"] = \"product\"\n",
    "    docs=product_chunks\n",
    "    embeddings = OllamaEmbeddings(\n",
    "            model=\"mxbai-embed-large\",\n",
    "            base_url=\"http://10.28.85.206:11434/\"\n",
    "        )\n",
    "    vectorstore = Chroma.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=\"chroma_db\",\n",
    "        )\n",
    "    vectorstore.persist()\n",
    "    retrieved_docs = vectorstore.similarity_search(state[\"question\"], k=5)\n",
    "    \n",
    "    return {\"context\":retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f040a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState2)->AgentState2:\n",
    "    rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    extra_rules = textwrap.dedent(\"\"\"\\\n",
    "        Answer requirements:\n",
    "        1. If any link is provided, wrap it in an anchor tag with target=\"_blank\".\n",
    "        2. Only use links that appear in the knowledge text files.\n",
    "        3. Do not invent links.\n",
    "\n",
    "        If the question is not related to accounting or the GL website, reply:\n",
    "        \"Please ask a question related to accounting or the GL website.\"\n",
    "\n",
    "        Concise accounting answer:\n",
    "    \"\"\")\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    base_prompt = rag_prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    full_prompt = f\"{base_prompt}\\n\\n{extra_rules}\"\n",
    "    answer=structured_llm.invoke(full_prompt)\n",
    "    return {'answer': answer}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fcb9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(AgentState2)\n",
    "\n",
    "graph.add_node(\"retriever\", retriever)\n",
    "graph.add_node(\"generate\",generate)\n",
    "\n",
    "graph.add_edge(START, \"retriever\")\n",
    "graph.add_edge(\"retriever\",\"generate\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "\n",
    "workflow2 = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "49118e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/muhammadahmad/DATA5/data-derive/generative-ai/chatboot/.venv/lib/python3.12/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer answer='To sign up for a new account, go to <a href=\"https://gl.vteamslabs.com/signup\" target=\"_blank\">https://gl.vteamslabs.com/signup</a>.\\nFill out the registration form with your name, email, and desired password.'\n"
     ]
    }
   ],
   "source": [
    "final_state=workflow2.invoke({\"question\":\"How do I create a new account (sign up)?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b8b2365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='To sign up for a new account, go to <a href=\"https://gl.vteamslabs.com/signup\" target=\"_blank\">https://gl.vteamslabs.com/signup</a>.\\n\\nFill out the registration form with your name, email, and desired password.'\n"
     ]
    }
   ],
   "source": [
    "print(final_state[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
